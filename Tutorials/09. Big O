Why does Assignment #9 have you sorting the same thing in several different ways?
It probably seems to you that all of them complete really quickly, and true, they're pretty interchangeable for an array of size 100.
Sometimes programmers have bigger challenges.  The human genome has ~3,000,000,000 base pairs to sort through.
You don't want to be sitting at your computer for 5 years while that executes.
So programmers have come up with a concept called Big O.
Big O is defined as the longest possible time a program could take to execute, worst-case scenario.
Your computer takes more time when it has to execute more actions, like comparing or assigning variables.
Getting Big O to be smaller is often the secret to making a 5-year task take 5 minutes.

Why is it called Big O?  It stands for order of magnitude and can also be written O(n).
What is an order of magnitude?  It's a power of 10.
Let's say you have jelly beans in a jar and you have to guess how many there are.
500 is a pretty good guess.
But honestly, anything between 100-900 is a pretty good guess.
If you guess 50, that's not very accurate.  If you guess 5,000, that's not very accurate.  If you guess 50,000, that's extremely inaccurate.
That's because 100-900 is all within one order of magnitude.  50 is one order of magnitude away.  5,000 is also.  50,000 is two orders of magnitude away.
In calculating the Big-O worst-case time taken by a program, programmers are okay with approximating.  They just want the order of magnitude.
Letting a program execute for 500 minutes isn't that much worse than 250 minutes.  But imagine letting it execute for 5,000 minutes??

Okay, so how do we calculate Big O for each of our sort functions?
Note that it's always dependent on the size of the array, which we'll call n.  If there are 100 elements, n=100.
Extract Sort
  You would need to cycle through the original array and pull out your target (number of actions = n).
  Then you would need to cycle through every element in the second array before you found its home (number of actions = n^2 because each element cycles through each other element).
  Thus, O(n) = n + n^2
  Which is basically the same as O(n) = n^2 for big lists.
Bubble Sort
  In a worst-case scenario, you would need to swap every element with every other element (number of actions = n^2).
  Thus, O(n) = n^2
Count Sort
  In a worst-case scenario, you would cycle through the original array and populate your 2D array (number of actions = n).
  Then you would cycle through your 2D array and populate your final array (number of actions = n).
  Thus, O(n) = 2n
  Which is basically the same as O(n) = n because it's within an order of magnitude.
  Even if you needed to cycle through your array a third time to find its numerical range, 3n is still within an order of magnitude.
  
What does all this mean?
It means that Count Sort is WAY more efficient for your computer's time than Extract and Bubble Sort because n is WAY less than n^2.
Even 2n, 3n, or 5n is WAY less than n^2.
So this approximation turns out to be pretty useful in figuring out which to use for big data.
As an example, let's say n = 10,000, and let's say each task takes 0.01 second.
You could get through O(n) = n = 10,000 tasks in 100 seconds.  That's about 2 minutes.
  This order of magnitude would say 100 seconds isn't too far off from 900 seconds, which is 15 minutes.
You could get through O(n) = n^2 = 100,000,000 tasks in 1,000,000 seconds.  That's about 11.5 days.
  This order of magnitude would say 1,000,000 seconds isn't too far off from 9,000,000 seconds, which is 3 months.
Given a context of 11.5 days, I would say 15 minutes and 2 minutes are basically the same.

Is it ever useful to use Bubble Sort?  Of course!
But you have to know that your data is NOT worst-case scenario - as in, it's very nearly sorted already.

There are even more ways to sort numbers.  One of the most efficient consists of breaking down a list into two smaller lists and then merging them.
You got to explore this in a future Loops project, where you combined two sorted lists.
For this, O(n) = n*log(n), which is better than Bubble but not quite as fast as Count Sort.
But Count Sort is only good for literal sorting from small to large.
Have you ever wondered how they sequence DNA?  3 billion base pairs in a single cell!
They have to arrange a library of A, G, C, and T in the correct order, not from small to large, but from end to end.
They break it down into smaller sections, assemble these smaller genomes, and then assemble them into a bigger genome, several times over.
Geneticists call it "shotgun sequencing."
